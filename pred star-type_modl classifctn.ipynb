{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Temperature         L       R    A_M Color Spectral_Class  Type\n",
      "0         3068  0.002400  0.1700  16.12   Red              M     0\n",
      "1         3042  0.000500  0.1542  16.60   Red              M     0\n",
      "2         2600  0.000300  0.1020  18.70   Red              M     0\n",
      "3         2800  0.000200  0.1600  16.65   Red              M     0\n",
      "4         1939  0.000138  0.1030  20.06   Red              M     0\n",
      "(240, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature     240 non-null    int64  \n",
      " 1   L               240 non-null    float64\n",
      " 2   R               240 non-null    float64\n",
      " 3   A_M             240 non-null    float64\n",
      " 4   Color           240 non-null    object \n",
      " 5   Spectral_Class  240 non-null    object \n",
      " 6   Type            240 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 11.3+ KB\n",
      "None\n",
      "Temperature       0\n",
      "L                 0\n",
      "R                 0\n",
      "A_M               0\n",
      "Color             0\n",
      "Spectral_Class    0\n",
      "Type              0\n",
      "dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [Temperature, L, R, A_M, Color, Spectral_Class, Type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('F:/python_venv/csv_files/Stars.csv')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.info()) # to get details about data\n",
    "print(df.isnull().sum()) # to check f any missing values\n",
    "print(df[df.duplicated()]) #to check duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "m=LabelBinarizer()\n",
    "df['Color']=m.fit_transform(df['Color'])\n",
    "df['Spectral_Class']=m.fit_transform(df['Spectral_Class'])\n",
    "df\n",
    "exp_var=df.drop(['Type'],axis=1)\n",
    "res_var=df[['Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(exp_var,res_var,train_size=0.8,\n",
    "                                               random_state=0,stratify=res_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.76        13\n",
      "           1       0.25      1.00      0.40         2\n",
      "           2       1.00      0.89      0.94         9\n",
      "           3       0.75      1.00      0.86         6\n",
      "           4       0.88      0.78      0.82         9\n",
      "           5       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.81      0.86      0.79        48\n",
      "weighted avg       0.91      0.81      0.84        48\n",
      "\n",
      "confusion matrix:\n",
      "[[8 5 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 8 0 0 0]\n",
      " [0 0 0 6 0 0]\n",
      " [0 0 0 2 7 0]\n",
      " [0 0 0 0 1 8]]\n",
      "accurcy score: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_venv\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "f:\\python_venv\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "mod1=LogisticRegression()\n",
    "a=mod1.fit(x_train,y_train)\n",
    "y_pred=mod1.predict(x_test)\n",
    "print(classification_report(y_pred,y_test))\n",
    "print('confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "print('accurcy score:',accuracy_score(y_pred,y_test))\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc curve: 0.9139371095892835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_test2=m.fit_transform(y_test)\n",
    "y_pred=m.transform(y_pred)\n",
    "print('roc-auc curve:',roc_auc_score(y_pred,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurcy score: 0.5416666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62         8\n",
      "           1       0.62      0.62      0.62         8\n",
      "           2       0.62      0.62      0.62         8\n",
      "           3       0.50      0.57      0.53         7\n",
      "           4       0.50      0.40      0.44        10\n",
      "           5       0.38      0.43      0.40         7\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.54      0.55      0.54        48\n",
      "weighted avg       0.54      0.54      0.54        48\n",
      "\n",
      "confusion matrix:\n",
      "[[5 3 0 0 0 0]\n",
      " [3 5 0 0 0 0]\n",
      " [0 0 5 3 0 0]\n",
      " [0 0 3 4 0 0]\n",
      " [0 0 0 1 4 5]\n",
      " [0 0 0 0 4 3]]\n",
      "roc-auc score: 0.727102053915276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-90b15c2eb2e5>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  mod2.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "mod2=KNeighborsClassifier(n_neighbors=5)\n",
    "mod2.fit(x_train,y_train)\n",
    "y_pred=mod2.predict(x_test)\n",
    "print('accurcy score:',accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))\n",
    "print('confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "\n",
    "y_pred=m.transform(y_pred)\n",
    "print('roc-auc score:',roc_auc_score(y_pred,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 1.0\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "\n",
      " confusion matrix:\n",
      "[[8 0 0 0 0 0]\n",
      " [0 8 0 0 0 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 0 8 0 0]\n",
      " [0 0 0 0 8 0]\n",
      " [0 0 0 0 0 8]]\n",
      "\n",
      " roc-auc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mod3=DecisionTreeClassifier(criterion='gini')\n",
    "mod3.fit(x_train,y_train)\n",
    "y_pred=mod3.predict(x_test)\n",
    "print('accuracy score:',accuracy_score(y_pred,y_test))\n",
    "print('\\n',classification_report(y_pred,y_test))\n",
    "print('\\n confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "\n",
    "y_pred=m.transform(y_pred)\n",
    "print('\\n roc-auc score:',roc_auc_score(y_pred,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-bdde4a979c33>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  mod4.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurcy score: 1.0\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "\n",
      " confusion matrix:\n",
      "[[8 0 0 0 0 0]\n",
      " [0 8 0 0 0 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 0 8 0 0]\n",
      " [0 0 0 0 8 0]\n",
      " [0 0 0 0 0 8]]\n",
      "\n",
      " roc-auc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "mod4=RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "mod4.fit(x_train,y_train)\n",
    "y_pred=mod4.predict(x_test)\n",
    "print('accurcy score:',accuracy_score(y_pred,y_test))\n",
    "print('\\n',classification_report(y_pred,y_test))\n",
    "print('\\n confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "\n",
    "y_pred=m.transform(y_pred)\n",
    "print('\\n roc-auc score:',roc_auc_score(y_pred,y_test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_venv\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      0.33      0.50        24\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.67      0.56      0.58        48\n",
      "weighted avg       1.00      0.67      0.75        48\n",
      "\n",
      "\n",
      " confusion matrix:\n",
      "[[8 0 0 0 0 0]\n",
      " [0 8 0 8 8 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_venv\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "mod5=AdaBoostClassifier(n_estimators=100,random_state=0)\n",
    "mod5.fit(x_train,y_train)\n",
    "y_pred=mod5.predict(x_test)\n",
    "print('accuracy score:',accuracy_score(y_pred,y_test))\n",
    "print('\\n',classification_report(y_pred,y_test))\n",
    "print('\\n confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "\n",
    "y_pred=m.transform(y_pred)\n",
    "#print('\\n roc-auc score:',roc_auc_score(y_pred,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python_venv\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurcy score: 1.0\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "\n",
      " confusion matrix:\n",
      "[[8 0 0 0 0 0]\n",
      " [0 8 0 0 0 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 0 8 0 0]\n",
      " [0 0 0 0 8 0]\n",
      " [0 0 0 0 0 8]]\n",
      "\n",
      " roc-auc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "mod6=GradientBoostingClassifier(n_estimators=200,random_state=0,max_depth=3)\n",
    "mod6.fit(x_train,y_train)\n",
    "y_pred=mod6.predict(x_test)\n",
    "print('accurcy score:',accuracy_score(y_pred,y_test))\n",
    "print('\\n',classification_report(y_pred,y_test))\n",
    "print('\\n confusion matrix:',confusion_matrix(y_pred,y_test),sep='\\n')\n",
    "\n",
    "y_pred=m.transform(y_pred)\n",
    "print('\\n roc-auc score:',roc_auc_score(y_pred,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'roc_auc_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-e6489eab6362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mCM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rainbow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Classification of models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python_venv\\env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'roc_auc_score'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,accuracy_score\n",
    "\n",
    "CM=pd.DataFrame([mod1,mod2,mod3,mod4,mod5,mod6],['Logistic regression',\n",
    "                                                'KNN classifier','Decision tree',\n",
    "                                                'Random forest','Adaboost',\n",
    "                                                 'Gradient boost classi.'])\n",
    "CM.columns=['roc-auc score']\n",
    "CM\n",
    "plt.figure(figsize=(11,5))\n",
    "sns.barplot(CM.index,CM.roc_auc_score,palette='rainbow')\n",
    "plt.title('Classification of models')"
   ]
  },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
